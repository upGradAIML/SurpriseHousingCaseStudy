{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'Surprise Housing - Part 1.ipynb'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the optimal value of alpha for ridge_doubled_doubled_doubled_doubled and lasso regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Ridge Regression, the optimal value of alpha is 200\n",
      "In Lasso Regression, the optimal value of alpha is 500\n"
     ]
    }
   ],
   "source": [
    "# Optimal value of alpha for ridge\n",
    "print('In Ridge Regression, the optimal value of alpha is', model_cv.best_params_['alpha'])\n",
    "\n",
    "# Optimal value of alphe for lasso\n",
    "print('In Lasso Regression, the optimal value of alpha is', model_cv_lasso.best_params_['alpha'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What will be the changes in the model if you choose double the value of alpha for both ridge and lasso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ralpha = 400\n",
    "ridge_doubled = Ridge(alpha=ralpha)\n",
    "ridge_doubled.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge_doubled_train = ridge_doubled.predict(X_train)\n",
    "y_pred_ridge_doubled_test = ridge_doubled.predict(X_test)\n",
    "\n",
    "metric2_doubled = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_ridge_doubled_train)\n",
    "metric2_doubled.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_ridge_doubled_test)\n",
    "metric2_doubled.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_ridge_doubled_train))\n",
    "metric2_doubled.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_ridge_doubled_test))\n",
    "metric2_doubled.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_ridge_doubled_train)\n",
    "metric2_doubled.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_ridge_doubled_test)\n",
    "metric2_doubled.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalpha = 1000\n",
    "lasso_doubled = Lasso(alpha=lalpha)\n",
    "lasso_doubled.fit(X_train, y_train)\n",
    "y_pred_lasso_doubled_train = lasso_doubled.predict(X_train)\n",
    "y_pred_lasso_doubled_test = lasso_doubled.predict(X_test)\n",
    "\n",
    "metric3_doubled = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_lasso_doubled_train)\n",
    "metric3_doubled.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_lasso_doubled_test)\n",
    "metric3_doubled.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_lasso_doubled_train))\n",
    "metric3_doubled.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_lasso_doubled_test))\n",
    "metric3_doubled.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_lasso_doubled_train)\n",
    "metric3_doubled.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_lasso_doubled_test)\n",
    "metric3_doubled.append(mse_test_lr**0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What will be the most important predictor variables after the change is implemented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea               10534.730475\n",
       "OverallQual             10450.014545\n",
       "2ndFlrSF                 7347.009310\n",
       "RoofMatl_WdShngl         7231.974776\n",
       "Neighborhood_NoRidge     6892.484145\n",
       "Name: Ridge, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Ridge] Original list of most important predictors (before doubling alpha)\n",
    "betas['Ridge'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table with doubled values\n",
    "betas_doubled = pd.DataFrame(index=X.columns)\n",
    "betas_doubled.rows = X.columns\n",
    "betas_doubled['Linear'] = lm.coef_\n",
    "betas_doubled['Ridge_Doubled'] = ridge_doubled.coef_\n",
    "betas_doubled['Lasso_Doubled'] = lasso_doubled.coef_\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#betas_doubled.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual             9146.386678\n",
       "GrLivArea               8691.378921\n",
       "Neighborhood_NoRidge    6361.309083\n",
       "Neighborhood_NridgHt    5674.340025\n",
       "1stFlrSF                5618.975207\n",
       "Name: Ridge_Doubled, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Ridge Doubled] List of most important predictors after doubling alpha\n",
    "betas_doubled['Ridge_Doubled'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Answer - Part 1:**\n",
    "- In Ridge, `OverallQual` and `GrLivArea` switched top two places when alpha was doubled.\n",
    "- `Neighborhood_NoRidge` came 3rd after being 5th before doubling alpha, followed by `Neighborhood_NridgHt`, which indicates that the location contributes a lot in the price.\n",
    "- `1stFlrSF` has taken over `2ndFlrSF`, indicating that price is mostly decided by the main floor area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoofMatl_CompShg    32722.709855\n",
       "GrLivArea           29737.474373\n",
       "RoofMatl_WdShngl    20224.204921\n",
       "RoofMatl_Tar&Grv    20030.873653\n",
       "RoofMatl_WdShake    13766.132756\n",
       "Name: Lasso, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Lasso] Original list of most important predictors (before doubling alpha)\n",
    "betas['Lasso'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea               27139.877611\n",
       "OverallQual             16569.350649\n",
       "Neighborhood_NridgHt     7429.544401\n",
       "Neighborhood_NoRidge     7142.238110\n",
       "GarageCars               6811.531363\n",
       "Name: Lasso_Doubled, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Lasso Doubled] Original list of most important predictors (before doubling alpha)\n",
    "betas_doubled['Lasso_Doubled'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Answer - Part 2:**\n",
    "- In Lasso, all roof materials types were dropped from top features.\n",
    "- `GrLivArea` came 1st after being 2nd before doubling alpha, followed by `OverallQual`.\n",
    "- `lasso` and `ridge` has predicted the same top 4 variables, meaning that the new (doubled) alpha values made both models the same.\n",
    "- `GarageCars` came in the fifth place. It was one of the highest correlated values to `SalePrice` before running regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**\n",
    "\n",
    "You have determined the optimal value of lambda for ridge and lasso regression during the assignment.\n",
    "- Now, which one will you choose to apply and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features are 246\n",
      "Lasso has selected 118 and dropped 128 features before doubling alpha\n",
      "Lasso has selected 154 and dropped 92 features after doubling alpha\n"
     ]
    }
   ],
   "source": [
    "# Features selected by Lasso\n",
    "features = betas[betas['Lasso'] != 0]\n",
    "features_in_double = betas_doubled[betas_doubled['Lasso_Doubled'] != 0]\n",
    "print('Total features are', betas.shape[0])\n",
    "print('Lasso has selected', betas.shape[0] - features.shape[0], 'and dropped',\n",
    "       features.shape[0], 'features before doubling alpha')\n",
    "print('Lasso has selected', betas_doubled.shape[0] - features_in_double.shape[0], 'and dropped', \n",
    "      features_in_double.shape[0], 'features after doubling alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table which contain all the metrics\n",
    "\n",
    "lr_table_doubled = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)'], \n",
    "        'Linear Regression': metric\n",
    "        }\n",
    "\n",
    "lr_metric_doubled = pd.DataFrame(lr_table_doubled ,columns = ['Metric', 'Linear Regression'] )\n",
    "\n",
    "rg_metric_doubled = pd.Series(metric2_doubled, name = 'Ridge Regression')\n",
    "ls_metric_doubled = pd.Series(metric3_doubled, name = 'Lasso Regression')\n",
    "\n",
    "final_metric_doubled = pd.concat([lr_metric_doubled, rg_metric_doubled, ls_metric_doubled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Ridge Regression</th>\n",
       "      <th>Lasso Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2 Score (Train)</td>\n",
       "      <td>9.492998e-01</td>\n",
       "      <td>9.042479e-01</td>\n",
       "      <td>9.237615e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2 Score (Test)</td>\n",
       "      <td>-1.608086e+21</td>\n",
       "      <td>8.591934e-01</td>\n",
       "      <td>8.444495e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RSS (Train)</td>\n",
       "      <td>3.235028e+11</td>\n",
       "      <td>6.109654e+11</td>\n",
       "      <td>4.864548e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RSS (Test)</td>\n",
       "      <td>4.532733e+33</td>\n",
       "      <td>3.968933e+11</td>\n",
       "      <td>4.384521e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSE (Train)</td>\n",
       "      <td>1.780025e+04</td>\n",
       "      <td>2.446220e+04</td>\n",
       "      <td>2.182772e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSE (Test)</td>\n",
       "      <td>3.216940e+15</td>\n",
       "      <td>3.010231e+04</td>\n",
       "      <td>3.163909e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Metric  Linear Regression  Ridge Regression  Lasso Regression\n",
       "0  R2 Score (Train)       9.492998e-01      9.042479e-01      9.237615e-01\n",
       "1   R2 Score (Test)      -1.608086e+21      8.591934e-01      8.444495e-01\n",
       "2       RSS (Train)       3.235028e+11      6.109654e+11      4.864548e+11\n",
       "3        RSS (Test)       4.532733e+33      3.968933e+11      4.384521e+11\n",
       "4       MSE (Train)       1.780025e+04      2.446220e+04      2.182772e+04\n",
       "5        MSE (Test)       3.216940e+15      3.010231e+04      3.163909e+04"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original metrics against alpha_ridge = 200 and alpha_lasso = 500\n",
    "final_metric.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Ridge Regression</th>\n",
       "      <th>Lasso Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2 Score (Train)</td>\n",
       "      <td>9.492998e-01</td>\n",
       "      <td>8.898002e-01</td>\n",
       "      <td>8.923762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2 Score (Test)</td>\n",
       "      <td>-1.608086e+21</td>\n",
       "      <td>8.579731e-01</td>\n",
       "      <td>8.411681e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RSS (Train)</td>\n",
       "      <td>3.235028e+11</td>\n",
       "      <td>7.031520e+11</td>\n",
       "      <td>6.867151e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RSS (Test)</td>\n",
       "      <td>4.532733e+33</td>\n",
       "      <td>4.003329e+11</td>\n",
       "      <td>4.477014e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSE (Train)</td>\n",
       "      <td>1.780025e+04</td>\n",
       "      <td>2.624289e+04</td>\n",
       "      <td>2.593435e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSE (Test)</td>\n",
       "      <td>3.216940e+15</td>\n",
       "      <td>3.023247e+04</td>\n",
       "      <td>3.197107e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Metric  Linear Regression  Ridge Regression  Lasso Regression\n",
       "0  R2 Score (Train)       9.492998e-01      8.898002e-01      8.923762e-01\n",
       "1   R2 Score (Test)      -1.608086e+21      8.579731e-01      8.411681e-01\n",
       "2       RSS (Train)       3.235028e+11      7.031520e+11      6.867151e+11\n",
       "3        RSS (Test)       4.532733e+33      4.003329e+11      4.477014e+11\n",
       "4       MSE (Train)       1.780025e+04      2.624289e+04      2.593435e+04\n",
       "5        MSE (Test)       3.216940e+15      3.023247e+04      3.197107e+04"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics after doubling alpha value for both ridge and alpha\n",
    "final_metric_doubled.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Answer:** \n",
    "- Ridge regression has higher R2 score, and lower gap between train and test sets.\n",
    "- Doubling alpha lowered R2 score by average of 2-3% and increased MSE in both models, which is not helpful.\n",
    "- Lasso's features selection is useful in case of large amount of variables. Doubling alpha also showed how Lasso has performed by dropping less features.\n",
    "- On the other hand, with lower MSE on Test set in Ridge `3.01` vs `3.16` in Lasso, this implies that Ridge performed better on unseen data.\n",
    "\n",
    "Lasso is preferred in this case study due to its ability to drop features that are less significant to `SalePrice`, and this is effective since we have a lot of variables (246) in this case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**\n",
    "\n",
    "After building the model, you realised that the five most important predictor variables in the lasso model are not available in the incoming data. You will now have to create another model excluding the five most important predictor variables. Which are the five most important predictor variables now?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoofMatl_CompShg    32722.709855\n",
       "GrLivArea           29737.474373\n",
       "RoofMatl_WdShngl    20224.204921\n",
       "RoofMatl_Tar&Grv    20030.873653\n",
       "RoofMatl_WdShake    13766.132756\n",
       "Name: Lasso, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_top5 = betas['Lasso'].sort_values(ascending=False).head(5)\n",
    "lasso_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X.drop(columns=['GrLivArea', 'RoofMatl_WdShngl', 'RoofMatl_Tar&Grv', 'RoofMatl_WdShake', 'RoofMatl_CompShg'], axis=1)\n",
    "\n",
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y, \n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 1.0, 2.0,\n",
       "                                   5.0, 10.0, 20, 50, 100, 200, 500, 1000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 1.0, 2.0,\n",
       "                                   5.0, 10.0, 20, 50, 100, 200, 500, 1000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 1.0, 2.0,\n",
       "                                   5.0, 10.0, 20, 50, 100, 200, 500, 1000]},\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5,\n",
    " 1.0, 2.0, 5.0, 10.0, 20, 50, 100, 200, 500, 1000]}\n",
    "\n",
    "# cross validation\n",
    "model_cv_lasso_new = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "model_cv_lasso_new.fit(X_train_new, y_train_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 500}\n"
     ]
    }
   ],
   "source": [
    "print(model_cv_lasso_new.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = model_cv_lasso_new.best_params_['alpha']\n",
    "lasso_new = Lasso(alpha=alpha)\n",
    "\n",
    "lasso_new.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_lasso_train_new = lasso_new.predict(X_train_new)\n",
    "y_pred_lasso_test_new = lasso_new.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table with new values\n",
    "betas_new = pd.DataFrame(index=X_new.columns)\n",
    "betas_new.rows = X_new.columns\n",
    "betas_new['Lasso_New'] = lasso_new.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Answer:** New top 5 features now are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2ndFlrSF                24211.243146\n",
       "1stFlrSF                18551.565585\n",
       "OverallQual             15063.322878\n",
       "GarageCars               7856.510694\n",
       "Neighborhood_NoRidge     7737.314025\n",
       "Name: Lasso_New, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas_new['Lasso_New'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4**\n",
    "\n",
    "- How can you make sure that a model is robust and generalisable?\n",
    "\n",
    "    **Answer:** \n",
    "    - When the model performs well on test data compared to an equivalent training data, it means that it's generalised well. This means also the model did not over or under fit the data.\n",
    "    - On the other hand, for a model to be robust, it should perform well on test (unseen) data when training data is noisy (e.g.: missing/null values), or has outliers or variations.\n",
    "\n",
    "##\n",
    "- What are the implications of the same for the accuracy of the model? and why?\n",
    "\n",
    "    **Answer:**\n",
    "    - Robustness (as defined above) goes opposite to accuracy, as for the model to be robust, it tends to be more complex, leading to lower bias, higher variance, and hence too much accuracy.\n",
    "    - There's always a tradeoff between bias and variance. To reach an optimal model, we'll sacrifice some robustness towards optimally predicting values that were not used to train the model, which is the measurement of the accuracy.\n",
    "##\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- In this case study, we cleaned, prepared and scaled the data before splitting into training and test sets, so that both are equivalent. So our model can easily be considered to be well generalised. Below values of accuracy proves this point.\n",
    "- If we wanted to make the model more robust, we could've split the data before cleaning, then train the model. In this case, the test set would include lots of noise (missing values). Then apply regularisation and testing different alpha values for both ridge and lasso.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Ridge Regression: 89.40%.\n",
      "\n",
      "Accuracy of Lasso Regression: 89.70%.\n"
     ]
    }
   ],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "Ridge_MAPE = MAPE(y_test, y_pred_ridge_test)\n",
    "Ridge_Accuracy = 100 - Ridge_MAPE\n",
    "print('Accuracy of Ridge Regression: {:0.2f}%.'.format(Ridge_Accuracy))\n",
    "print('')\n",
    "Lasso_MAPE = MAPE(y_test,y_pred_lasso_test)\n",
    "Lasso_Accuracy = 100 - Lasso_MAPE\n",
    "print('Accuracy of Lasso Regression: {:0.2f}%.'.format(Lasso_Accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
